{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20515, 146)\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\"\"\"\"\n",
    "Function to read in the csv file \n",
    "and output an esri shapefile\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv('sent2_training_data_10m.csv',header=0)\n",
    "\n",
    "df53 = df[(df['zone'] == 53)].copy()\n",
    "print df53.shape\n",
    "\n",
    "\n",
    "df53['geometry'] = [Point(xy) for xy in zip(df53['x'], df53['y'])]\n",
    "# create a df with all of the attributes \n",
    "df1 = df53[['geometry','site', 'x', 'y', 'chm', 'std_1', 'Min_1', 'Max_1', 'count_1', 'perc5_1', 'perc10_1', 'perc25_1', \n",
    "            'perc50_1', 'perc75_1', 'perc80_1', 'perc95_1', 'perc99_1', 'zone']]\n",
    "# create the geo data frame        \n",
    "df1 = gpd.GeoDataFrame(df1, geometry='geometry')\n",
    "# set the projection and datum\n",
    "df1.crs = \"+init=epsg:32753\"\n",
    "\n",
    "# save out the geo data frame in esri shapefile format.\n",
    "#df1.to_file(\"training_z53.shp\", driver='ESRI Shapefile') \n",
    "\n",
    "df1_prj = df1.copy()\n",
    "\n",
    "df1_prj['geometry'] = df1[\"geometry\"].to_crs(epsg=4326)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127485, 146)\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\"\"\"\"\n",
    "Function to read in the csv file \n",
    "and output an esri shapefile\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv('sent2_training_data_10m.csv',header=0)\n",
    "\n",
    "df52 = df[(df['zone'] == 52)].copy()\n",
    "print df52.shape\n",
    "\n",
    "\n",
    "df52['geometry'] = [Point(xy) for xy in zip(df52['x'], df52['y'])]\n",
    "# create a df with all of the attributes \n",
    "df2 = df52[['geometry','site', 'x', 'y', 'chm', 'std_1', 'Min_1', 'Max_1', 'count_1', 'perc5_1', 'perc10_1', 'perc25_1', \n",
    "            'perc50_1', 'perc75_1', 'perc80_1', 'perc95_1', 'perc99_1', 'zone']]\n",
    "# create the geo data frame        \n",
    "df2 = gpd.GeoDataFrame(df2, geometry='geometry')\n",
    "# set the projection and datum\n",
    "df2.crs = \"+init=epsg:32752\"\n",
    "# save out the geo data frame in esri shapefile format.\n",
    "#df3.to_file(\"training_z52.shp\", driver='ESRI Shapefile') \n",
    "\n",
    "df2_prj = df2.copy()\n",
    "\n",
    "df2_prj['geometry'] = df2[\"geometry\"].to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(148000, 18)\n",
      "(148000, 18)\n"
     ]
    }
   ],
   "source": [
    "# concatenate the two dataframes and then create a geodataframe to export.\n",
    "gdf = pd.concat([df1_prj, df2_prj])\n",
    "print gdf.shape\n",
    "# create a geodataframe from the reprojected layers\n",
    "TrainData = gpd.GeoDataFrame(gdf, geometry='geometry')\n",
    "# define the projection and datum GCS_WGS84\n",
    "TrainData.crs = \"+init=epsg:4326\"\n",
    "print TrainData.shape\n",
    "TrainData.to_file(\"Train_Sentinel-2_10m_data_GCS_WGS84.shp\", driver='ESRI Shapefile') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is System\n",
      " Volume Serial Number is 12FA-D4D7\n",
      "\n",
      " Directory of C:\\Users\\grants\\code\\old_growth\\sen2_l8\\zonal_stats\\s2_10m_combined\n",
      "\n",
      "18/02/2019  09:04 AM    <DIR>          .\n",
      "18/02/2019  09:04 AM    <DIR>          ..\n",
      "18/02/2019  08:58 AM    <DIR>          .ipynb_checkpoints\n",
      "17/02/2019  10:31 AM            22,732 Band_Importance_Score.pdf\n",
      "03/02/2019  12:24 PM            13,657 combine_s2_10m_datasets.ipynb\n",
      "18/02/2019  08:56 AM       359,516,453 combined_data_S2_10m_int32_clean.csv\n",
      "09/02/2019  09:05 AM    <DIR>          final_model_10m\n",
      "18/02/2019  08:17 AM            49,021 make_int32_bit_training_and_validation_data_s2.ipynb\n",
      "18/02/2019  09:04 AM            12,158 make_training_val_shp_files.ipynb\n",
      "18/02/2019  04:37 AM    <DIR>          old_stuff_to_delete\n",
      "18/02/2019  09:01 AM       181,492,098 sent2_training_data_10m.csv\n",
      "17/02/2019  07:23 AM       106,441,957 sent2_training_data_10m_surf_ref_bands_only.csv\n",
      "18/02/2019  09:01 AM        45,372,618 sent2_val_data_10m.csv\n",
      "17/02/2019  10:32 AM           236,342 Sklearn_random_forest_regression_Code_Sentinel-2_combined_10m.ipynb\n",
      "18/02/2019  08:13 AM    <DIR>          stage01_02\n",
      "28/01/2019  05:28 PM    <DIR>          stage03\n",
      "18/02/2019  09:02 AM                10 Train_Sentinel-2_10m_data_GCS_WGS84.cpg\n",
      "18/02/2019  09:04 AM        49,432,577 Train_Sentinel-2_10m_data_GCS_WGS84.dbf\n",
      "18/02/2019  09:02 AM               143 Train_Sentinel-2_10m_data_GCS_WGS84.prj\n",
      "18/02/2019  09:04 AM         4,144,100 Train_Sentinel-2_10m_data_GCS_WGS84.shp\n",
      "18/02/2019  09:04 AM         1,184,100 Train_Sentinel-2_10m_data_GCS_WGS84.shx\n",
      "18/02/2019  09:02 AM             1,798 train_val_data_split.ipynb\n",
      "18/02/2019  08:58 AM             7,158 Untitled.ipynb\n",
      "23/01/2019  05:23 AM           115,492 Validation_Sentinel-2.ipynb\n",
      "              17 File(s)    748,042,414 bytes\n",
      "               7 Dir(s)   1,301,889,024 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'Unnamed: 0.1', 'site', 'x', 'y', 'chm', 'std_1', 'Min_1', 'Max_1', 'count_1', 'perc5_1', 'perc10_1', 'perc25_1', 'perc50_1', 'perc75_1', 'perc80_1', 'perc95_1', 'perc99_1', 'cov', 'psB1a', 'psB2a', 'psB3a', 'psB4a', 'psB5a', 'psB6a', 'psB7a', 'psB8a', 'psB9a', 'psB10a', 'ratio32a', 'ratio42a', 'ratio43a', 'ratio52a', 'ratio53a', 'ratio54a', 'ratio62a', 'ratio63a', 'ratio64a', 'ratio65a', 'ratio109a', 'GSAVIa', 'GNDVIa', 'CVIa', 'NDGIa', 'RIa', 'NBRa', 'NDIIa', 'GDVIa', 'MSAVIa', 'DVIa', 'SAVIa', 'NDVIa', 'MSRa', 'CIgreena', 'NDRE1a', 'NDRE2a', 'CIrededgea', 'psB1d', 'psB2d', 'psB3d', 'psB4d', 'psB5d', 'psB6d', 'psB7d', 'psB8d', 'psB9d', 'psB10d', 'ratio32d', 'ratio42d', 'ratio43d', 'ratio52d', 'ratio53d', 'ratio54d', 'ratio62d', 'ratio63d', 'ratio64d', 'ratio65d', 'ratio109d', 'GSAVId', 'GNDVId', 'CVId', 'NDGId', 'RId', 'NBRd', 'NDIId', 'GDVId', 'MSAVId', 'DVId', 'SAVId', 'NDVId', 'MSRd', 'CIgreend', 'NDRE1d', 'NDRE2d', 'CIrededged', 'zone']\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\"\"\"\"\n",
    "Function to read in the csv file \n",
    "and output an esri shapefile\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv('',header=0)\n",
    "print list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5072, 146)\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\"\"\"\"\n",
    "Function to read in the csv file \n",
    "and output an esri shapefile\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv('sent2_val_data_10m.csv',header=0)\n",
    "\n",
    "df53 = df[(df['zone'] == 53)].copy()\n",
    "print df53.shape\n",
    "\n",
    "\n",
    "df53['geometry'] = [Point(xy) for xy in zip(df53['x'], df53['y'])]\n",
    "# create a df with all of the attributes \n",
    "df1 = df53[['geometry','site', 'x', 'y', 'chm', 'std_1', 'Min_1', 'Max_1', 'count_1', 'perc5_1', 'perc10_1', 'perc25_1', \n",
    "            'perc50_1', 'perc75_1', 'perc80_1', 'perc95_1', 'perc99_1', 'zone']]\n",
    "# create the geo data frame        \n",
    "df1 = gpd.GeoDataFrame(df1, geometry='geometry')\n",
    "# set the projection and datum\n",
    "df1.crs = \"+init=epsg:32753\"\n",
    "\n",
    "# save out the geo data frame in esri shapefile format.\n",
    "#df1.to_file(\"training_z53.shp\", driver='ESRI Shapefile') \n",
    "\n",
    "df1_prj = df1.copy()\n",
    "\n",
    "df1_prj['geometry'] = df1[\"geometry\"].to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31928, 146)\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\"\"\"\"\n",
    "Function to read in the csv file \n",
    "and output an esri shapefile\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv('sent2_val_data_10m.csv',header=0)\n",
    "\n",
    "df52 = df[(df['zone'] == 52)].copy()\n",
    "print df52.shape\n",
    "\n",
    "\n",
    "df52['geometry'] = [Point(xy) for xy in zip(df52['x'], df52['y'])]\n",
    "# create a df with all of the attributes \n",
    "df2 = df52[['geometry','site', 'x', 'y', 'chm', 'std_1', 'Min_1', 'Max_1', 'count_1', 'perc5_1', 'perc10_1', 'perc25_1', \n",
    "            'perc50_1', 'perc75_1', 'perc80_1', 'perc95_1', 'perc99_1', 'zone']]\n",
    "# create the geo data frame        \n",
    "df2 = gpd.GeoDataFrame(df2, geometry='geometry')\n",
    "# set the projection and datum\n",
    "df2.crs = \"+init=epsg:32752\"\n",
    "# save out the geo data frame in esri shapefile format.\n",
    "#df3.to_file(\"training_z52.shp\", driver='ESRI Shapefile') \n",
    "\n",
    "df2_prj = df2.copy()\n",
    "\n",
    "df2_prj['geometry'] = df2[\"geometry\"].to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37000, 18)\n",
      "(37000, 18)\n"
     ]
    }
   ],
   "source": [
    "# concatenate the two dataframes and then create a geodataframe to export.\n",
    "gdf = pd.concat([df1_prj, df2_prj])\n",
    "print gdf.shape\n",
    "# create a geodataframe from the reprojected layers\n",
    "TrainData = gpd.GeoDataFrame(gdf, geometry='geometry')\n",
    "# define the projection and datum GCS_WGS84\n",
    "TrainData.crs = \"+init=epsg:4326\"\n",
    "print TrainData.shape\n",
    "TrainData.to_file(\"Val_Sentinel-2_10m_data_GCS_WGS84.shp\", driver='ESRI Shapefile') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'C:\\\\Users\\\\grants\\\\code\\\\old_growth\\\\sen2_l8\\\\zonal_stats\\\\s2_10m_combined'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is System\n",
      " Volume Serial Number is 12FA-D4D7\n",
      "\n",
      " Directory of C:\\Users\\grants\\code\\old_growth\\sen2_l8\\zonal_stats\\s2_10m_combined\n",
      "\n",
      "18/02/2019  08:07 AM    <DIR>          .\n",
      "18/02/2019  08:07 AM    <DIR>          ..\n",
      "17/02/2019  05:56 AM    <DIR>          .ipynb_checkpoints\n",
      "17/02/2019  10:31 AM            22,732 Band_Importance_Score.pdf\n",
      "03/02/2019  12:24 PM            13,657 combine_s2_10m_datasets.ipynb\n",
      "18/02/2019  04:04 AM       181,641,507 combined_training_data_s2_10m.csv\n",
      "18/02/2019  04:02 AM        45,404,840 combined_val_data_s2_10m.csv\n",
      "09/02/2019  09:05 AM    <DIR>          final_model_10m\n",
      "17/02/2019  08:31 AM            32,837 make_int32_bit_training_and_validation_data_s2.ipynb\n",
      "18/02/2019  08:07 AM            11,037 make_training_val_shp_files.ipynb\n",
      "18/02/2019  04:37 AM    <DIR>          old_stuff_to_delete\n",
      "17/02/2019  07:23 AM       106,441,957 sent2_training_data_10m_surf_ref_bands_only.csv\n",
      "17/02/2019  10:32 AM           236,342 Sklearn_random_forest_regression_Code_Sentinel-2_combined_10m.ipynb\n",
      "18/02/2019  06:45 AM    <DIR>          stage01_02\n",
      "28/01/2019  05:28 PM    <DIR>          stage03\n",
      "18/02/2019  08:06 AM                10 Train_Sentinel-2_10m_data_GCS_WGS84.cpg\n",
      "18/02/2019  08:07 AM        44,236,873 Train_Sentinel-2_10m_data_GCS_WGS84.dbf\n",
      "18/02/2019  08:06 AM               143 Train_Sentinel-2_10m_data_GCS_WGS84.prj\n",
      "18/02/2019  08:07 AM         3,708,532 Train_Sentinel-2_10m_data_GCS_WGS84.shp\n",
      "18/02/2019  08:07 AM         1,059,652 Train_Sentinel-2_10m_data_GCS_WGS84.shx\n",
      "18/02/2019  08:07 AM                10 Val_Sentinel-2_10m_data_GCS_WGS84.cpg\n",
      "18/02/2019  08:08 AM        12,358,577 Val_Sentinel-2_10m_data_GCS_WGS84.dbf\n",
      "18/02/2019  08:07 AM               143 Val_Sentinel-2_10m_data_GCS_WGS84.prj\n",
      "18/02/2019  08:08 AM         1,036,100 Val_Sentinel-2_10m_data_GCS_WGS84.shp\n",
      "18/02/2019  08:08 AM           296,100 Val_Sentinel-2_10m_data_GCS_WGS84.shx\n",
      "23/01/2019  05:23 AM           115,492 Validation_Sentinel-2.ipynb\n",
      "              19 File(s)    396,616,541 bytes\n",
      "               7 Dir(s)     915,013,632 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
